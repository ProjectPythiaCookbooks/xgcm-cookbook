{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"images/thumbnail.png\" alt=\"thumbnail\" width=\"300\"/>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MITgcm ECCOv4 Example"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Overview\n",
    "This notebook demonstrates how to use [xarray](http://xarray.pydata.org/en/latest/) and\n",
    "[xgcm](http://xgcm.readthedocs.org) to analyze data from the [ECCO v4r3](https://ecco.jpl.nasa.gov/products/latest/)\n",
    "ocean state estimate."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prerequisites\n",
    "\n",
    "| Concepts | Importance | Notes |\n",
    "| --- | --- | --- |\n",
    "| [Xgcm](https://xgcm.readthedocs.io/en/latest/) | Necessary | Using Grid object for finite volume analysis |\n",
    "| [Intake](https://intake.readthedocs.io/en/latest/?badge=latest#) | Helpful | Opening catalogs |\n",
    "| [Zarr](http://zarr.readthedocs.io) | Helpful | Its similarities and differences, compared to NetCDF |\n",
    "| [Intro to Cartopy](https://foundations.projectpythia.org/core/cartopy/cartopy.html) | Helpful | Projections and features |\n",
    "| [Matplotlib Basics](https://foundations.projectpythia.org/core/matplotlib/matplotlib-basics.html) | Helpful | Subplots, axes, etc.\n",
    "\n",
    "- **Time to learn**: 90 minutes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ECCOv4 data analysis and visualization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import intake\n",
    "import numpy as np\n",
    "import xarray as xr\n",
    "import cartopy as cart\n",
    "import pyresample\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The ECCOv4r3 data was converted from its raw MDS (.data / .meta file) format to zarr format, using the\n",
    "[xmitgcm](http://xmitgcm.readthedocs.io) package. [Zarr](http://zarr.readthedocs.io) is a powerful data storage format\n",
    "that can be thought of as an alternative to HDF. In contrast to HDF, Zarr works very well with cloud object storage.\n",
    "Zarr is currently usable in Python, Java, C++, and Julia. It is likely that Zarr will form the basis of the next major\n",
    "version of the netCDF library.\n",
    "\n",
    "If you're curious, here are some resources to learn more about Zarr:\n",
    "  - https://zarr.readthedocs.io/en/stable/tutorial.html\n",
    "  - https://speakerdeck.com/rabernat/pangeo-zarr-cloud-data-storage\n",
    "  - https://mrocklin.github.com/blog/work/2018/02/06/hdf-in-the-cloud\n",
    "\n",
    "The ECCO Zarr data currently lives in [Google Cloud Storage](https://cloud.google.com/storage/) as part of the\n",
    "[Pangeo Data Catalog](http://catalog.pangeo.io/). This means we can open the whole dataset using one line of code.\n",
    "\n",
    "This takes a bit of time to run because the metadata must be downloaded and parsed. The type of object returned is\n",
    "an [Xarray dataset](https://xarray.pydata.org/en/latest/user-guide/data-structures.html#dataset)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Bad Request: https://storage.googleapis.com/download/storage/v1/b/pangeo-ecco-eccov4r3/o/eccov4r3%2F.zmetadata?alt=media\nUser project specified in the request is invalid.",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mValueError\u001B[0m                                Traceback (most recent call last)",
      "Input \u001B[0;32mIn [2]\u001B[0m, in \u001B[0;36m<cell line: 2>\u001B[0;34m()\u001B[0m\n\u001B[1;32m      1\u001B[0m cat \u001B[38;5;241m=\u001B[39m intake\u001B[38;5;241m.\u001B[39mopen_catalog(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mhttps://raw.githubusercontent.com/pangeo-data/pangeo-datastore/master/intake-catalogs/ocean.yaml\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[0;32m----> 2\u001B[0m ds \u001B[38;5;241m=\u001B[39m \u001B[43mcat\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mECCOv4r3\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mto_dask\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m      3\u001B[0m ds\n",
      "File \u001B[0;32m~/miniconda3/envs/xgcm-cookbook-dev/lib/python3.10/site-packages/intake_xarray/base.py:69\u001B[0m, in \u001B[0;36mDataSourceMixin.to_dask\u001B[0;34m(self)\u001B[0m\n\u001B[1;32m     67\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mto_dask\u001B[39m(\u001B[38;5;28mself\u001B[39m):\n\u001B[1;32m     68\u001B[0m     \u001B[38;5;124;03m\"\"\"Return xarray object where variables are dask arrays\"\"\"\u001B[39;00m\n\u001B[0;32m---> 69\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mread_chunked\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/miniconda3/envs/xgcm-cookbook-dev/lib/python3.10/site-packages/intake_xarray/base.py:44\u001B[0m, in \u001B[0;36mDataSourceMixin.read_chunked\u001B[0;34m(self)\u001B[0m\n\u001B[1;32m     42\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mread_chunked\u001B[39m(\u001B[38;5;28mself\u001B[39m):\n\u001B[1;32m     43\u001B[0m     \u001B[38;5;124;03m\"\"\"Return xarray object (which will have chunks)\"\"\"\u001B[39;00m\n\u001B[0;32m---> 44\u001B[0m     \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_load_metadata\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     45\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_ds\n",
      "File \u001B[0;32m~/miniconda3/envs/xgcm-cookbook-dev/lib/python3.10/site-packages/intake/source/base.py:236\u001B[0m, in \u001B[0;36mDataSourceBase._load_metadata\u001B[0;34m(self)\u001B[0m\n\u001B[1;32m    234\u001B[0m \u001B[38;5;124;03m\"\"\"load metadata only if needed\"\"\"\u001B[39;00m\n\u001B[1;32m    235\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_schema \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[0;32m--> 236\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_schema \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_get_schema\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    237\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mdtype \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_schema\u001B[38;5;241m.\u001B[39mdtype\n\u001B[1;32m    238\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mshape \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_schema\u001B[38;5;241m.\u001B[39mshape\n",
      "File \u001B[0;32m~/miniconda3/envs/xgcm-cookbook-dev/lib/python3.10/site-packages/intake_xarray/base.py:18\u001B[0m, in \u001B[0;36mDataSourceMixin._get_schema\u001B[0;34m(self)\u001B[0m\n\u001B[1;32m     15\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39murlpath \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_get_cache(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39murlpath)[\u001B[38;5;241m0\u001B[39m]\n\u001B[1;32m     17\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_ds \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[0;32m---> 18\u001B[0m     \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_open_dataset\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     20\u001B[0m     metadata \u001B[38;5;241m=\u001B[39m {\n\u001B[1;32m     21\u001B[0m         \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mdims\u001B[39m\u001B[38;5;124m'\u001B[39m: \u001B[38;5;28mdict\u001B[39m(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_ds\u001B[38;5;241m.\u001B[39mdims),\n\u001B[1;32m     22\u001B[0m         \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mdata_vars\u001B[39m\u001B[38;5;124m'\u001B[39m: {k: \u001B[38;5;28mlist\u001B[39m(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_ds[k]\u001B[38;5;241m.\u001B[39mcoords)\n\u001B[1;32m     23\u001B[0m                       \u001B[38;5;28;01mfor\u001B[39;00m k \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_ds\u001B[38;5;241m.\u001B[39mdata_vars\u001B[38;5;241m.\u001B[39mkeys()},\n\u001B[1;32m     24\u001B[0m         \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mcoords\u001B[39m\u001B[38;5;124m'\u001B[39m: \u001B[38;5;28mtuple\u001B[39m(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_ds\u001B[38;5;241m.\u001B[39mcoords\u001B[38;5;241m.\u001B[39mkeys()),\n\u001B[1;32m     25\u001B[0m     }\n\u001B[1;32m     26\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mgetattr\u001B[39m(\u001B[38;5;28mself\u001B[39m, \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mon_server\u001B[39m\u001B[38;5;124m'\u001B[39m, \u001B[38;5;28;01mFalse\u001B[39;00m):\n",
      "File \u001B[0;32m~/miniconda3/envs/xgcm-cookbook-dev/lib/python3.10/site-packages/intake_xarray/xzarr.py:46\u001B[0m, in \u001B[0;36mZarrSource._open_dataset\u001B[0;34m(self)\u001B[0m\n\u001B[1;32m     44\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_ds \u001B[38;5;241m=\u001B[39m xr\u001B[38;5;241m.\u001B[39mopen_mfdataset(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39murlpath, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkw)\n\u001B[1;32m     45\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m---> 46\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_ds \u001B[38;5;241m=\u001B[39m \u001B[43mxr\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mopen_dataset\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43murlpath\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkw\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/miniconda3/envs/xgcm-cookbook-dev/lib/python3.10/site-packages/xarray/backends/api.py:495\u001B[0m, in \u001B[0;36mopen_dataset\u001B[0;34m(filename_or_obj, engine, chunks, cache, decode_cf, mask_and_scale, decode_times, decode_timedelta, use_cftime, concat_characters, decode_coords, drop_variables, backend_kwargs, *args, **kwargs)\u001B[0m\n\u001B[1;32m    483\u001B[0m decoders \u001B[38;5;241m=\u001B[39m _resolve_decoders_kwargs(\n\u001B[1;32m    484\u001B[0m     decode_cf,\n\u001B[1;32m    485\u001B[0m     open_backend_dataset_parameters\u001B[38;5;241m=\u001B[39mbackend\u001B[38;5;241m.\u001B[39mopen_dataset_parameters,\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m    491\u001B[0m     decode_coords\u001B[38;5;241m=\u001B[39mdecode_coords,\n\u001B[1;32m    492\u001B[0m )\n\u001B[1;32m    494\u001B[0m overwrite_encoded_chunks \u001B[38;5;241m=\u001B[39m kwargs\u001B[38;5;241m.\u001B[39mpop(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124moverwrite_encoded_chunks\u001B[39m\u001B[38;5;124m\"\u001B[39m, \u001B[38;5;28;01mNone\u001B[39;00m)\n\u001B[0;32m--> 495\u001B[0m backend_ds \u001B[38;5;241m=\u001B[39m \u001B[43mbackend\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mopen_dataset\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m    496\u001B[0m \u001B[43m    \u001B[49m\u001B[43mfilename_or_obj\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    497\u001B[0m \u001B[43m    \u001B[49m\u001B[43mdrop_variables\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mdrop_variables\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    498\u001B[0m \u001B[43m    \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mdecoders\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    499\u001B[0m \u001B[43m    \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    500\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    501\u001B[0m ds \u001B[38;5;241m=\u001B[39m _dataset_from_backend_dataset(\n\u001B[1;32m    502\u001B[0m     backend_ds,\n\u001B[1;32m    503\u001B[0m     filename_or_obj,\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m    510\u001B[0m     \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs,\n\u001B[1;32m    511\u001B[0m )\n\u001B[1;32m    512\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m ds\n",
      "File \u001B[0;32m~/miniconda3/envs/xgcm-cookbook-dev/lib/python3.10/site-packages/xarray/backends/zarr.py:800\u001B[0m, in \u001B[0;36mZarrBackendEntrypoint.open_dataset\u001B[0;34m(self, filename_or_obj, mask_and_scale, decode_times, concat_characters, decode_coords, drop_variables, use_cftime, decode_timedelta, group, mode, synchronizer, consolidated, chunk_store, storage_options, stacklevel)\u001B[0m\n\u001B[1;32m    780\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mopen_dataset\u001B[39m(\n\u001B[1;32m    781\u001B[0m     \u001B[38;5;28mself\u001B[39m,\n\u001B[1;32m    782\u001B[0m     filename_or_obj,\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m    796\u001B[0m     stacklevel\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m3\u001B[39m,\n\u001B[1;32m    797\u001B[0m ):\n\u001B[1;32m    799\u001B[0m     filename_or_obj \u001B[38;5;241m=\u001B[39m _normalize_path(filename_or_obj)\n\u001B[0;32m--> 800\u001B[0m     store \u001B[38;5;241m=\u001B[39m \u001B[43mZarrStore\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mopen_group\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m    801\u001B[0m \u001B[43m        \u001B[49m\u001B[43mfilename_or_obj\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    802\u001B[0m \u001B[43m        \u001B[49m\u001B[43mgroup\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mgroup\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    803\u001B[0m \u001B[43m        \u001B[49m\u001B[43mmode\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mmode\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    804\u001B[0m \u001B[43m        \u001B[49m\u001B[43msynchronizer\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43msynchronizer\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    805\u001B[0m \u001B[43m        \u001B[49m\u001B[43mconsolidated\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mconsolidated\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    806\u001B[0m \u001B[43m        \u001B[49m\u001B[43mconsolidate_on_close\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mFalse\u001B[39;49;00m\u001B[43m,\u001B[49m\n\u001B[1;32m    807\u001B[0m \u001B[43m        \u001B[49m\u001B[43mchunk_store\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mchunk_store\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    808\u001B[0m \u001B[43m        \u001B[49m\u001B[43mstorage_options\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mstorage_options\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    809\u001B[0m \u001B[43m        \u001B[49m\u001B[43mstacklevel\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mstacklevel\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m+\u001B[39;49m\u001B[43m \u001B[49m\u001B[38;5;241;43m1\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[1;32m    810\u001B[0m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    812\u001B[0m     store_entrypoint \u001B[38;5;241m=\u001B[39m StoreBackendEntrypoint()\n\u001B[1;32m    813\u001B[0m     \u001B[38;5;28;01mwith\u001B[39;00m close_on_error(store):\n",
      "File \u001B[0;32m~/miniconda3/envs/xgcm-cookbook-dev/lib/python3.10/site-packages/xarray/backends/zarr.py:368\u001B[0m, in \u001B[0;36mZarrStore.open_group\u001B[0;34m(cls, store, mode, synchronizer, group, consolidated, consolidate_on_close, chunk_store, storage_options, append_dim, write_region, safe_chunks, stacklevel)\u001B[0m\n\u001B[1;32m    365\u001B[0m         zarr_group \u001B[38;5;241m=\u001B[39m zarr\u001B[38;5;241m.\u001B[39mopen_group(store, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mopen_kwargs)\n\u001B[1;32m    366\u001B[0m \u001B[38;5;28;01melif\u001B[39;00m consolidated:\n\u001B[1;32m    367\u001B[0m     \u001B[38;5;66;03m# TODO: an option to pass the metadata_key keyword\u001B[39;00m\n\u001B[0;32m--> 368\u001B[0m     zarr_group \u001B[38;5;241m=\u001B[39m \u001B[43mzarr\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mopen_consolidated\u001B[49m\u001B[43m(\u001B[49m\u001B[43mstore\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mopen_kwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    369\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m    370\u001B[0m     zarr_group \u001B[38;5;241m=\u001B[39m zarr\u001B[38;5;241m.\u001B[39mopen_group(store, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mopen_kwargs)\n",
      "File \u001B[0;32m~/miniconda3/envs/xgcm-cookbook-dev/lib/python3.10/site-packages/zarr/convenience.py:1304\u001B[0m, in \u001B[0;36mopen_consolidated\u001B[0;34m(store, metadata_key, mode, **kwargs)\u001B[0m\n\u001B[1;32m   1299\u001B[0m         \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(\n\u001B[1;32m   1300\u001B[0m             \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mpath must be provided to open a Zarr 3.x consolidated store\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m   1301\u001B[0m         )\n\u001B[1;32m   1303\u001B[0m \u001B[38;5;66;03m# setup metadata store\u001B[39;00m\n\u001B[0;32m-> 1304\u001B[0m meta_store \u001B[38;5;241m=\u001B[39m \u001B[43mConsolidatedStoreClass\u001B[49m\u001B[43m(\u001B[49m\u001B[43mstore\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mmetadata_key\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mmetadata_key\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1306\u001B[0m \u001B[38;5;66;03m# pass through\u001B[39;00m\n\u001B[1;32m   1307\u001B[0m chunk_store \u001B[38;5;241m=\u001B[39m kwargs\u001B[38;5;241m.\u001B[39mpop(\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mchunk_store\u001B[39m\u001B[38;5;124m'\u001B[39m, \u001B[38;5;28;01mNone\u001B[39;00m) \u001B[38;5;129;01mor\u001B[39;00m store\n",
      "File \u001B[0;32m~/miniconda3/envs/xgcm-cookbook-dev/lib/python3.10/site-packages/zarr/storage.py:2853\u001B[0m, in \u001B[0;36mConsolidatedMetadataStore.__init__\u001B[0;34m(self, store, metadata_key)\u001B[0m\n\u001B[1;32m   2850\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mstore \u001B[38;5;241m=\u001B[39m Store\u001B[38;5;241m.\u001B[39m_ensure_store(store)\n\u001B[1;32m   2852\u001B[0m \u001B[38;5;66;03m# retrieve consolidated metadata\u001B[39;00m\n\u001B[0;32m-> 2853\u001B[0m meta \u001B[38;5;241m=\u001B[39m json_loads(\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mstore\u001B[49m\u001B[43m[\u001B[49m\u001B[43mmetadata_key\u001B[49m\u001B[43m]\u001B[49m)\n\u001B[1;32m   2855\u001B[0m \u001B[38;5;66;03m# check format of consolidated metadata\u001B[39;00m\n\u001B[1;32m   2856\u001B[0m consolidated_format \u001B[38;5;241m=\u001B[39m meta\u001B[38;5;241m.\u001B[39mget(\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mzarr_consolidated_format\u001B[39m\u001B[38;5;124m'\u001B[39m, \u001B[38;5;28;01mNone\u001B[39;00m)\n",
      "File \u001B[0;32m~/miniconda3/envs/xgcm-cookbook-dev/lib/python3.10/site-packages/zarr/storage.py:1369\u001B[0m, in \u001B[0;36mFSStore.__getitem__\u001B[0;34m(self, key)\u001B[0m\n\u001B[1;32m   1367\u001B[0m key \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_normalize_key(key)\n\u001B[1;32m   1368\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m-> 1369\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mmap\u001B[49m\u001B[43m[\u001B[49m\u001B[43mkey\u001B[49m\u001B[43m]\u001B[49m\n\u001B[1;32m   1370\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mexceptions \u001B[38;5;28;01mas\u001B[39;00m e:\n\u001B[1;32m   1371\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mKeyError\u001B[39;00m(key) \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01me\u001B[39;00m\n",
      "File \u001B[0;32m~/miniconda3/envs/xgcm-cookbook-dev/lib/python3.10/site-packages/fsspec/mapping.py:137\u001B[0m, in \u001B[0;36mFSMap.__getitem__\u001B[0;34m(self, key, default)\u001B[0m\n\u001B[1;32m    135\u001B[0m k \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_key_to_str(key)\n\u001B[1;32m    136\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m--> 137\u001B[0m     result \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mfs\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mcat\u001B[49m\u001B[43m(\u001B[49m\u001B[43mk\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    138\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mmissing_exceptions:\n\u001B[1;32m    139\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m default \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n",
      "File \u001B[0;32m~/miniconda3/envs/xgcm-cookbook-dev/lib/python3.10/site-packages/fsspec/asyn.py:86\u001B[0m, in \u001B[0;36msync_wrapper.<locals>.wrapper\u001B[0;34m(*args, **kwargs)\u001B[0m\n\u001B[1;32m     83\u001B[0m \u001B[38;5;129m@functools\u001B[39m\u001B[38;5;241m.\u001B[39mwraps(func)\n\u001B[1;32m     84\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mwrapper\u001B[39m(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs):\n\u001B[1;32m     85\u001B[0m     \u001B[38;5;28mself\u001B[39m \u001B[38;5;241m=\u001B[39m obj \u001B[38;5;129;01mor\u001B[39;00m args[\u001B[38;5;241m0\u001B[39m]\n\u001B[0;32m---> 86\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43msync\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mloop\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mfunc\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/miniconda3/envs/xgcm-cookbook-dev/lib/python3.10/site-packages/fsspec/asyn.py:66\u001B[0m, in \u001B[0;36msync\u001B[0;34m(loop, func, timeout, *args, **kwargs)\u001B[0m\n\u001B[1;32m     64\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m FSTimeoutError \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mreturn_result\u001B[39;00m\n\u001B[1;32m     65\u001B[0m \u001B[38;5;28;01melif\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(return_result, \u001B[38;5;167;01mBaseException\u001B[39;00m):\n\u001B[0;32m---> 66\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m return_result\n\u001B[1;32m     67\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m     68\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m return_result\n",
      "File \u001B[0;32m~/miniconda3/envs/xgcm-cookbook-dev/lib/python3.10/site-packages/fsspec/asyn.py:26\u001B[0m, in \u001B[0;36m_runner\u001B[0;34m(event, coro, result, timeout)\u001B[0m\n\u001B[1;32m     24\u001B[0m     coro \u001B[38;5;241m=\u001B[39m asyncio\u001B[38;5;241m.\u001B[39mwait_for(coro, timeout\u001B[38;5;241m=\u001B[39mtimeout)\n\u001B[1;32m     25\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m---> 26\u001B[0m     result[\u001B[38;5;241m0\u001B[39m] \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mawait\u001B[39;00m coro\n\u001B[1;32m     27\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mException\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m ex:\n\u001B[1;32m     28\u001B[0m     result[\u001B[38;5;241m0\u001B[39m] \u001B[38;5;241m=\u001B[39m ex\n",
      "File \u001B[0;32m~/miniconda3/envs/xgcm-cookbook-dev/lib/python3.10/site-packages/fsspec/asyn.py:398\u001B[0m, in \u001B[0;36mAsyncFileSystem._cat\u001B[0;34m(self, path, recursive, on_error, batch_size, **kwargs)\u001B[0m\n\u001B[1;32m    396\u001B[0m     ex \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mnext\u001B[39m(\u001B[38;5;28mfilter\u001B[39m(is_exception, out), \u001B[38;5;28;01mFalse\u001B[39;00m)\n\u001B[1;32m    397\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m ex:\n\u001B[0;32m--> 398\u001B[0m         \u001B[38;5;28;01mraise\u001B[39;00m ex\n\u001B[1;32m    399\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m (\n\u001B[1;32m    400\u001B[0m     \u001B[38;5;28mlen\u001B[39m(paths) \u001B[38;5;241m>\u001B[39m \u001B[38;5;241m1\u001B[39m\n\u001B[1;32m    401\u001B[0m     \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(path, \u001B[38;5;28mlist\u001B[39m)\n\u001B[1;32m    402\u001B[0m     \u001B[38;5;129;01mor\u001B[39;00m paths[\u001B[38;5;241m0\u001B[39m] \u001B[38;5;241m!=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_strip_protocol(path)\n\u001B[1;32m    403\u001B[0m ):\n\u001B[1;32m    404\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m {\n\u001B[1;32m    405\u001B[0m         k: v\n\u001B[1;32m    406\u001B[0m         \u001B[38;5;28;01mfor\u001B[39;00m k, v \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mzip\u001B[39m(paths, out)\n\u001B[1;32m    407\u001B[0m         \u001B[38;5;28;01mif\u001B[39;00m on_error \u001B[38;5;241m!=\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124momit\u001B[39m\u001B[38;5;124m\"\u001B[39m \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m is_exception(v)\n\u001B[1;32m    408\u001B[0m     }\n",
      "File \u001B[0;32m~/miniconda3/envs/xgcm-cookbook-dev/lib/python3.10/asyncio/tasks.py:408\u001B[0m, in \u001B[0;36mwait_for\u001B[0;34m(fut, timeout)\u001B[0m\n\u001B[1;32m    405\u001B[0m loop \u001B[38;5;241m=\u001B[39m events\u001B[38;5;241m.\u001B[39mget_running_loop()\n\u001B[1;32m    407\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m timeout \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[0;32m--> 408\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;01mawait\u001B[39;00m fut\n\u001B[1;32m    410\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m timeout \u001B[38;5;241m<\u001B[39m\u001B[38;5;241m=\u001B[39m \u001B[38;5;241m0\u001B[39m:\n\u001B[1;32m    411\u001B[0m     fut \u001B[38;5;241m=\u001B[39m ensure_future(fut, loop\u001B[38;5;241m=\u001B[39mloop)\n",
      "File \u001B[0;32m~/miniconda3/envs/xgcm-cookbook-dev/lib/python3.10/site-packages/gcsfs/core.py:781\u001B[0m, in \u001B[0;36mGCSFileSystem._cat_file\u001B[0;34m(self, path, start, end, **kwargs)\u001B[0m\n\u001B[1;32m    779\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m    780\u001B[0m     head \u001B[38;5;241m=\u001B[39m {}\n\u001B[0;32m--> 781\u001B[0m headers, out \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mawait\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_call(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mGET\u001B[39m\u001B[38;5;124m\"\u001B[39m, u2, headers\u001B[38;5;241m=\u001B[39mhead)\n\u001B[1;32m    782\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m out\n",
      "File \u001B[0;32m~/miniconda3/envs/xgcm-cookbook-dev/lib/python3.10/site-packages/gcsfs/core.py:392\u001B[0m, in \u001B[0;36mGCSFileSystem._call\u001B[0;34m(self, method, path, json_out, info_out, *args, **kwargs)\u001B[0m\n\u001B[1;32m    387\u001B[0m \u001B[38;5;28;01masync\u001B[39;00m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m_call\u001B[39m(\n\u001B[1;32m    388\u001B[0m     \u001B[38;5;28mself\u001B[39m, method, path, \u001B[38;5;241m*\u001B[39margs, json_out\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mFalse\u001B[39;00m, info_out\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mFalse\u001B[39;00m, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs\n\u001B[1;32m    389\u001B[0m ):\n\u001B[1;32m    390\u001B[0m     logger\u001B[38;5;241m.\u001B[39mdebug(\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mmethod\u001B[38;5;241m.\u001B[39mupper()\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m: \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mpath\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m, \u001B[39m\u001B[38;5;132;01m{\u001B[39;00margs\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m, \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mkwargs\u001B[38;5;241m.\u001B[39mget(\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mheaders\u001B[39m\u001B[38;5;124m'\u001B[39m)\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m\"\u001B[39m)\n\u001B[0;32m--> 392\u001B[0m     status, headers, info, contents \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mawait\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_request(\n\u001B[1;32m    393\u001B[0m         method, path, \u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs\n\u001B[1;32m    394\u001B[0m     )\n\u001B[1;32m    395\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m json_out:\n\u001B[1;32m    396\u001B[0m         \u001B[38;5;28;01mreturn\u001B[39;00m json\u001B[38;5;241m.\u001B[39mloads(contents)\n",
      "File \u001B[0;32m~/miniconda3/envs/xgcm-cookbook-dev/lib/python3.10/site-packages/decorator.py:221\u001B[0m, in \u001B[0;36mdecorate.<locals>.fun\u001B[0;34m(*args, **kw)\u001B[0m\n\u001B[1;32m    219\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m kwsyntax:\n\u001B[1;32m    220\u001B[0m     args, kw \u001B[38;5;241m=\u001B[39m fix(args, kw, sig)\n\u001B[0;32m--> 221\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;01mawait\u001B[39;00m caller(func, \u001B[38;5;241m*\u001B[39m(extras \u001B[38;5;241m+\u001B[39m args), \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkw)\n",
      "File \u001B[0;32m~/miniconda3/envs/xgcm-cookbook-dev/lib/python3.10/site-packages/gcsfs/retry.py:115\u001B[0m, in \u001B[0;36mretry_request\u001B[0;34m(func, retries, *args, **kwargs)\u001B[0m\n\u001B[1;32m    113\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m retry \u001B[38;5;241m>\u001B[39m \u001B[38;5;241m0\u001B[39m:\n\u001B[1;32m    114\u001B[0m         \u001B[38;5;28;01mawait\u001B[39;00m asyncio\u001B[38;5;241m.\u001B[39msleep(\u001B[38;5;28mmin\u001B[39m(random\u001B[38;5;241m.\u001B[39mrandom() \u001B[38;5;241m+\u001B[39m \u001B[38;5;241m2\u001B[39m \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39m (retry \u001B[38;5;241m-\u001B[39m \u001B[38;5;241m1\u001B[39m), \u001B[38;5;241m32\u001B[39m))\n\u001B[0;32m--> 115\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;01mawait\u001B[39;00m func(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[1;32m    116\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m (\n\u001B[1;32m    117\u001B[0m     HttpError,\n\u001B[1;32m    118\u001B[0m     requests\u001B[38;5;241m.\u001B[39mexceptions\u001B[38;5;241m.\u001B[39mRequestException,\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m    121\u001B[0m     aiohttp\u001B[38;5;241m.\u001B[39mclient_exceptions\u001B[38;5;241m.\u001B[39mClientError,\n\u001B[1;32m    122\u001B[0m ) \u001B[38;5;28;01mas\u001B[39;00m e:\n\u001B[1;32m    123\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m (\n\u001B[1;32m    124\u001B[0m         \u001B[38;5;28misinstance\u001B[39m(e, HttpError)\n\u001B[1;32m    125\u001B[0m         \u001B[38;5;129;01mand\u001B[39;00m e\u001B[38;5;241m.\u001B[39mcode \u001B[38;5;241m==\u001B[39m \u001B[38;5;241m400\u001B[39m\n\u001B[1;32m    126\u001B[0m         \u001B[38;5;129;01mand\u001B[39;00m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mrequester pays\u001B[39m\u001B[38;5;124m\"\u001B[39m \u001B[38;5;129;01min\u001B[39;00m e\u001B[38;5;241m.\u001B[39mmessage\n\u001B[1;32m    127\u001B[0m     ):\n",
      "File \u001B[0;32m~/miniconda3/envs/xgcm-cookbook-dev/lib/python3.10/site-packages/gcsfs/core.py:384\u001B[0m, in \u001B[0;36mGCSFileSystem._request\u001B[0;34m(self, method, path, headers, json, data, *args, **kwargs)\u001B[0m\n\u001B[1;32m    381\u001B[0m info \u001B[38;5;241m=\u001B[39m r\u001B[38;5;241m.\u001B[39mrequest_info  \u001B[38;5;66;03m# for debug only\u001B[39;00m\n\u001B[1;32m    382\u001B[0m contents \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mawait\u001B[39;00m r\u001B[38;5;241m.\u001B[39mread()\n\u001B[0;32m--> 384\u001B[0m \u001B[43mvalidate_response\u001B[49m\u001B[43m(\u001B[49m\u001B[43mstatus\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcontents\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mpath\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43margs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    385\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m status, headers, info, contents\n",
      "File \u001B[0;32m~/miniconda3/envs/xgcm-cookbook-dev/lib/python3.10/site-packages/gcsfs/retry.py:100\u001B[0m, in \u001B[0;36mvalidate_response\u001B[0;34m(status, content, path, args)\u001B[0m\n\u001B[1;32m     98\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m requests\u001B[38;5;241m.\u001B[39mexceptions\u001B[38;5;241m.\u001B[39mProxyError()\n\u001B[1;32m     99\u001B[0m \u001B[38;5;28;01melif\u001B[39;00m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124minvalid\u001B[39m\u001B[38;5;124m\"\u001B[39m \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mstr\u001B[39m(msg):\n\u001B[0;32m--> 100\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mBad Request: \u001B[39m\u001B[38;5;132;01m%s\u001B[39;00m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;132;01m%s\u001B[39;00m\u001B[38;5;124m\"\u001B[39m \u001B[38;5;241m%\u001B[39m (path, msg))\n\u001B[1;32m    101\u001B[0m \u001B[38;5;28;01melif\u001B[39;00m error:\n\u001B[1;32m    102\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m HttpError(error)\n",
      "\u001B[0;31mValueError\u001B[0m: Bad Request: https://storage.googleapis.com/download/storage/v1/b/pangeo-ecco-eccov4r3/o/eccov4r3%2F.zmetadata?alt=media\nUser project specified in the request is invalid."
     ]
    }
   ],
   "source": [
    "cat = intake.open_catalog(\"https://raw.githubusercontent.com/pangeo-data/pangeo-datastore/master/intake-catalogs/ocean.yaml\")\n",
    "ds = cat.ECCOv4r3.to_dask()\n",
    "ds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that no data has been actually downloaded yet. Xarray uses the approach of _lazy evaluation_, in which loading\n",
    "of data and execution of computations is delayed as long as possible (i.e. until data is actually needed for a plot).\n",
    "The data are represented symbolically as [dask arrays](http://docs.dask.org/en/latest/array.html).\n",
    "\n",
    "For example:\n",
    "\n",
    "    SALT       (time, k, face, j, i) float32 dask.array<shape=(288, 50, 13, 90, 90), chunksize=(1, 50, 13, 90, 90)>\n",
    "\n",
    "The full shape of the array is (288, 50, 13, 90, 90), which is quite large. However, the _chunksize_ is\n",
    "(1, 50, 13, 90, 90). Here the chunks correspond to the individual granuales of data (objects) in cloud storage. The\n",
    "chunk is the minimum amount of data we can read at one time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'ds' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "Input \u001B[0;32mIn [3]\u001B[0m, in \u001B[0;36m<cell line: 2>\u001B[0;34m()\u001B[0m\n\u001B[1;32m      1\u001B[0m \u001B[38;5;66;03m# a trick to make things work a bit faster\u001B[39;00m\n\u001B[0;32m----> 2\u001B[0m coords \u001B[38;5;241m=\u001B[39m \u001B[43mds\u001B[49m\u001B[38;5;241m.\u001B[39mcoords\u001B[38;5;241m.\u001B[39mto_dataset()\u001B[38;5;241m.\u001B[39mreset_coords()\n\u001B[1;32m      3\u001B[0m ds \u001B[38;5;241m=\u001B[39m ds\u001B[38;5;241m.\u001B[39mreset_coords(drop\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mTrue\u001B[39;00m)\n",
      "\u001B[0;31mNameError\u001B[0m: name 'ds' is not defined"
     ]
    }
   ],
   "source": [
    "# a trick to make things work a bit faster\n",
    "coords = ds.coords.to_dataset().reset_coords()\n",
    "ds = ds.reset_coords(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualizing Data\n",
    "\n",
    "#### A Direct Plot\n",
    "\n",
    "Let's try to visualize something simple: the `Depth` variable. Here is how the data are stored:\n",
    "\n",
    "    Depth      (face, j, i) float32 dask.array<shape=(13, 90, 90), chunksize=(13, 90, 90)>\n",
    "\n",
    "Although depth is a 2D field, there is an extra, dimension (`face`) corresponding to the LLC face number. Let's use\n",
    "xarray's built-in plotting functions to plot each face individually."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'coords' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "Input \u001B[0;32mIn [4]\u001B[0m, in \u001B[0;36m<cell line: 1>\u001B[0;34m()\u001B[0m\n\u001B[0;32m----> 1\u001B[0m \u001B[43mcoords\u001B[49m\u001B[38;5;241m.\u001B[39mDepth\u001B[38;5;241m.\u001B[39mplot(col\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mface\u001B[39m\u001B[38;5;124m'\u001B[39m, col_wrap\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m5\u001B[39m)\n",
      "\u001B[0;31mNameError\u001B[0m: name 'coords' is not defined"
     ]
    }
   ],
   "source": [
    "coords.Depth.plot(col='face', col_wrap=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This view is not the most useful. It reflects how the data are arranged logically, rather than geographically.\n",
    "\n",
    "#### A Pretty Map\n",
    "\n",
    "To make plotting easier, we can define a quick function to plot the data in a more geographically friendly way.\n",
    "Eventually these plotting functions may be provided by the gcmplots package: <https://github.com/xecco/gcmplots>.\n",
    "For now, it is easy enough to roll our own."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "class LLCMapper:\n",
    "\n",
    "    def __init__(self, ds, dx=0.25, dy=0.25):\n",
    "        # Extract LLC 2D coordinates\n",
    "        lons_1d = ds.XC.values.ravel()\n",
    "        lats_1d = ds.YC.values.ravel()\n",
    "\n",
    "        # Define original grid\n",
    "        self.orig_grid = pyresample.geometry.SwathDefinition(lons=lons_1d, lats=lats_1d)\n",
    "\n",
    "        # Longitudes latitudes to which we will we interpolate\n",
    "        lon_tmp = np.arange(-180, 180, dx) + dx/2\n",
    "        lat_tmp = np.arange(-90, 90, dy) + dy/2\n",
    "\n",
    "        # Define the lat lon points of the two parts.\n",
    "        self.new_grid_lon, self.new_grid_lat = np.meshgrid(lon_tmp, lat_tmp)\n",
    "        self.new_grid  = pyresample.geometry.GridDefinition(lons=self.new_grid_lon,\n",
    "                                                            lats=self.new_grid_lat)\n",
    "\n",
    "    def __call__(self, da, ax=None, projection=cart.crs.Robinson(), lon_0=-60, **plt_kwargs):\n",
    "\n",
    "        assert set(da.dims) == set(['face', 'j', 'i']), \"da must have dimensions ['face', 'j', 'i']\"\n",
    "\n",
    "        if ax is None:\n",
    "            fig, ax = plt.subplots(figsize=(12, 6), subplot_kw={'projection': projection})\n",
    "        else:\n",
    "            m = plt.axes(projection=projection)\n",
    "\n",
    "        field = pyresample.kd_tree.resample_nearest(self.orig_grid, da.values,\n",
    "                                                    self.new_grid,\n",
    "                                                    radius_of_influence=100000,\n",
    "                                                    fill_value=None)\n",
    "\n",
    "        vmax = plt_kwargs.pop('vmax', field.max())\n",
    "        vmin = plt_kwargs.pop('vmin', field.min())\n",
    "\n",
    "\n",
    "        x,y = self.new_grid_lon, self.new_grid_lat\n",
    "\n",
    "        # Find index where data is splitted for mapping\n",
    "        split_lon_idx = round(x.shape[1]/(360/(lon_0 if lon_0>0 else lon_0+360)))\n",
    "\n",
    "\n",
    "        p = ax.pcolormesh(x[:,:split_lon_idx], y[:,:split_lon_idx], field[:,:split_lon_idx],\n",
    "                          vmax=vmax, vmin=vmin, transform=cart.crs.PlateCarree(), zorder=1, **plt_kwargs)\n",
    "        p = ax.pcolormesh(x[:,split_lon_idx:], y[:,split_lon_idx:], field[:,split_lon_idx:],\n",
    "                          vmax=vmax, vmin=vmin, transform=cart.crs.PlateCarree(), zorder=2, **plt_kwargs)\n",
    "\n",
    "        ax.add_feature(cart.feature.LAND, facecolor='0.5', zorder=3)\n",
    "        label = ''\n",
    "        if da.name is not None:\n",
    "            label = da.name\n",
    "        if 'units' in da.attrs:\n",
    "            label += ' [%s]' % da.attrs['units']\n",
    "        cb = plt.colorbar(p, shrink=0.4, label=label)\n",
    "        return ax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'coords' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "Input \u001B[0;32mIn [6]\u001B[0m, in \u001B[0;36m<cell line: 1>\u001B[0;34m()\u001B[0m\n\u001B[0;32m----> 1\u001B[0m mapper \u001B[38;5;241m=\u001B[39m LLCMapper(\u001B[43mcoords\u001B[49m)\n\u001B[1;32m      2\u001B[0m mapper(coords\u001B[38;5;241m.\u001B[39mDepth)\n",
      "\u001B[0;31mNameError\u001B[0m: name 'coords' is not defined"
     ]
    }
   ],
   "source": [
    "mapper = LLCMapper(coords)\n",
    "mapper(coords.Depth);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can use this with any 2D cell-centered LLC variable.\n",
    "\n",
    "### Selecting data\n",
    "\n",
    "The entire ECCOv4e3 dataset is contained in a single `Xarray.Dataset` object. How do we find a view specific pieces\n",
    "of data? This is handled by Xarray's [indexing and selecting\n",
    "functions](http://xarray.pydata.org/en/latest/indexing.html). To get the SST from January 2000, we do this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'ds' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "Input \u001B[0;32mIn [7]\u001B[0m, in \u001B[0;36m<cell line: 1>\u001B[0;34m()\u001B[0m\n\u001B[0;32m----> 1\u001B[0m sst \u001B[38;5;241m=\u001B[39m \u001B[43mds\u001B[49m\u001B[38;5;241m.\u001B[39mTHETA\u001B[38;5;241m.\u001B[39msel(time\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124m2000-01-15\u001B[39m\u001B[38;5;124m'\u001B[39m, k\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m0\u001B[39m)\n\u001B[1;32m      2\u001B[0m sst\n",
      "\u001B[0;31mNameError\u001B[0m: name 'ds' is not defined"
     ]
    }
   ],
   "source": [
    "sst = ds.THETA.sel(time='2000-01-15', k=0)\n",
    "sst"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Still no data has been actually downloaded. That doesn't happen until we call `.load()` explicitly or try to\n",
    "make a plot."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'mapper' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "Input \u001B[0;32mIn [8]\u001B[0m, in \u001B[0;36m<cell line: 1>\u001B[0;34m()\u001B[0m\n\u001B[0;32m----> 1\u001B[0m \u001B[43mmapper\u001B[49m(sst, cmap\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mRdBu_r\u001B[39m\u001B[38;5;124m'\u001B[39m)\n",
      "\u001B[0;31mNameError\u001B[0m: name 'mapper' is not defined"
     ]
    }
   ],
   "source": [
    "mapper(sst, cmap='RdBu_r');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Do some Calculations\n",
    "\n",
    "Now let's start doing something besides just plotting the existing data. For example, let's calculate the\n",
    "time-mean SST."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'ds' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "Input \u001B[0;32mIn [9]\u001B[0m, in \u001B[0;36m<cell line: 1>\u001B[0;34m()\u001B[0m\n\u001B[0;32m----> 1\u001B[0m mean_sst \u001B[38;5;241m=\u001B[39m \u001B[43mds\u001B[49m\u001B[38;5;241m.\u001B[39mTHETA\u001B[38;5;241m.\u001B[39msel(k\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m0\u001B[39m)\u001B[38;5;241m.\u001B[39mmean(dim\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mtime\u001B[39m\u001B[38;5;124m'\u001B[39m)\n\u001B[1;32m      2\u001B[0m mean_sst\n",
      "\u001B[0;31mNameError\u001B[0m: name 'ds' is not defined"
     ]
    }
   ],
   "source": [
    "mean_sst = ds.THETA.sel(k=0).mean(dim='time')\n",
    "mean_sst"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As usual, no data was loaded. Instead, `mean_sst` is a symbolic representation of the data that needs to be pulled\n",
    "and the computations that need to be executed to produce the desired result. In this case, the 288 original chunks\n",
    "all need to be read from cloud storage. Dask coordinates this automatically for us. But it does take some time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%time mean_sst.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mapper(mean_sst, cmap='RdBu_r');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Speeding things up with a Dask Cluster\n",
    "\n",
    "How can we speed things up? In general, the main bottleneck for this type of data analysis is the speed with which\n",
    "we can read the data. With cloud storage, the access is highly parallelizable.\n",
    "\n",
    "From a Pangeo environment, we can create a [Dask cluster](https://distributed.dask.org/en/latest/) to spread the\n",
    "work out amongst many compute nodes. This works on both HPC and cloud. In the cloud, the compute nodes are\n",
    "provisioned on the fly and can be shut down as soon as we are done with our analysis.\n",
    "\n",
    "The code below will create a cluster with up to five compute nodes. These will be ramped up and down based on\n",
    "demand. It can take a few minutes to provision our nodes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from dask_gateway import Gateway\n",
    "from dask.distributed import Client"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dask Cluster setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "No dask-gateway address provided or found in configuration",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mValueError\u001B[0m                                Traceback (most recent call last)",
      "Input \u001B[0;32mIn [11]\u001B[0m, in \u001B[0;36m<cell line: 1>\u001B[0;34m()\u001B[0m\n\u001B[0;32m----> 1\u001B[0m gateway \u001B[38;5;241m=\u001B[39m \u001B[43mGateway\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m      2\u001B[0m cluster \u001B[38;5;241m=\u001B[39m gateway\u001B[38;5;241m.\u001B[39mnew_cluster()\n\u001B[1;32m      3\u001B[0m cluster\u001B[38;5;241m.\u001B[39madapt(minimum\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m1\u001B[39m, maximum\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m5\u001B[39m)\n",
      "File \u001B[0;32m~/miniconda3/envs/xgcm-cookbook-dev2/lib/python3.10/site-packages/dask_gateway/client.py:282\u001B[0m, in \u001B[0;36mGateway.__init__\u001B[0;34m(self, address, proxy_address, public_address, auth, asynchronous, loop)\u001B[0m\n\u001B[1;32m    280\u001B[0m     address \u001B[38;5;241m=\u001B[39m format_template(dask\u001B[38;5;241m.\u001B[39mconfig\u001B[38;5;241m.\u001B[39mget(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mgateway.address\u001B[39m\u001B[38;5;124m\"\u001B[39m))\n\u001B[1;32m    281\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m address \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[0;32m--> 282\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(\n\u001B[1;32m    283\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mNo dask-gateway address provided or found in configuration\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m    284\u001B[0m     )\n\u001B[1;32m    285\u001B[0m address \u001B[38;5;241m=\u001B[39m address\u001B[38;5;241m.\u001B[39mrstrip(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m/\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[1;32m    287\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m public_address \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n",
      "\u001B[0;31mValueError\u001B[0m: No dask-gateway address provided or found in configuration"
     ]
    }
   ],
   "source": [
    "gateway = Gateway()\n",
    "cluster = gateway.new_cluster()\n",
    "cluster.adapt(minimum=1, maximum=5)\n",
    "cluster"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we re-run the mean calculation. Note how the dashboard helps us visualize what the cluster is doing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'ds' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "File \u001B[0;32m<timed eval>:1\u001B[0m, in \u001B[0;36m<module>\u001B[0;34m\u001B[0m\n",
      "\u001B[0;31mNameError\u001B[0m: name 'ds' is not defined"
     ]
    }
   ],
   "source": [
    "%time ds.THETA.isel(k=0).mean(dim='time').load()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Spatially-Integrated Heat Content Anomaly\n",
    "\n",
    "Now let's do something harder. We will calculate the horizontally integrated heat content anomaly for the full\n",
    "3D model domain."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'ds' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "Input \u001B[0;32mIn [13]\u001B[0m, in \u001B[0;36m<cell line: 2>\u001B[0;34m()\u001B[0m\n\u001B[1;32m      1\u001B[0m \u001B[38;5;66;03m# the monthly climatology\u001B[39;00m\n\u001B[0;32m----> 2\u001B[0m theta_clim \u001B[38;5;241m=\u001B[39m \u001B[43mds\u001B[49m\u001B[38;5;241m.\u001B[39mTHETA\u001B[38;5;241m.\u001B[39mgroupby(\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mtime.month\u001B[39m\u001B[38;5;124m'\u001B[39m)\u001B[38;5;241m.\u001B[39mmean(dim\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mtime\u001B[39m\u001B[38;5;124m'\u001B[39m)\n\u001B[1;32m      3\u001B[0m \u001B[38;5;66;03m# the anomaly\u001B[39;00m\n\u001B[1;32m      4\u001B[0m theta_anom \u001B[38;5;241m=\u001B[39m ds\u001B[38;5;241m.\u001B[39mTHETA\u001B[38;5;241m.\u001B[39mgroupby(\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mtime.month\u001B[39m\u001B[38;5;124m'\u001B[39m) \u001B[38;5;241m-\u001B[39m theta_clim\n",
      "\u001B[0;31mNameError\u001B[0m: name 'ds' is not defined"
     ]
    }
   ],
   "source": [
    "# the monthly climatology\n",
    "theta_clim = ds.THETA.groupby('time.month').mean(dim='time')\n",
    "# the anomaly\n",
    "theta_anom = ds.THETA.groupby('time.month') - theta_clim\n",
    "rho0 = 1029\n",
    "cp = 3994\n",
    "ohc = rho0 * cp * (theta_anom *\n",
    "                   coords.rA *\n",
    "                   coords.hFacC).sum(dim=['face', 'j', 'i'])\n",
    "ohc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'ohc' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "Input \u001B[0;32mIn [14]\u001B[0m, in \u001B[0;36m<cell line: 2>\u001B[0;34m()\u001B[0m\n\u001B[1;32m      1\u001B[0m \u001B[38;5;66;03m# actually load the data\u001B[39;00m\n\u001B[0;32m----> 2\u001B[0m \u001B[43mohc\u001B[49m\u001B[38;5;241m.\u001B[39mload()\n\u001B[1;32m      3\u001B[0m \u001B[38;5;66;03m# put the depth coordinate back for plotting purposes\u001B[39;00m\n\u001B[1;32m      4\u001B[0m ohc\u001B[38;5;241m.\u001B[39mcoords[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mZ\u001B[39m\u001B[38;5;124m'\u001B[39m] \u001B[38;5;241m=\u001B[39m coords\u001B[38;5;241m.\u001B[39mZ\n",
      "\u001B[0;31mNameError\u001B[0m: name 'ohc' is not defined"
     ]
    }
   ],
   "source": [
    "# actually load the data\n",
    "ohc.load()\n",
    "# put the depth coordinate back for plotting purposes\n",
    "ohc.coords['Z'] = coords.Z\n",
    "ohc.swap_dims({'k': 'Z'}).transpose().plot(vmax=1e20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Further complicated computations via Xgcm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import xgcm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Spatial Derivatives: Heat Budget\n",
    "\n",
    "As our final exercise, we will do something much more complicated. We will compute the time-mean convergence of\n",
    "vertically-integrated heat fluxes. This is hard for several reasons.\n",
    "\n",
    "The first reason for this being hard is because it involves variables located at different grid points. Following MITgcm\n",
    "conventions, xmitgcm (which produced this dataset) labels the center point with the coordinates `j, i`, the\n",
    "u-velocity point as `j, i_g`, and the v-velocity point as `j_g, i`. The horizontal advective heat flux variables are:\n",
    "\n",
    "    ADVx_TH    (time, k, face, j, i_g) float32 dask.array<shape=(288, 50, 13, 90, 90), chunksize=(1, 50, 13, 90, 90)>\n",
    "    ADVy_TH    (time, k, face, j_g, i) float32 dask.array<shape=(288, 50, 13, 90, 90), chunksize=(1, 50, 13, 90, 90)>\n",
    "\n",
    "Xarray won't allow us to add or multiply variables that have different dimensions, and xarray by itself doesn't\n",
    "understand how to transform from one grid position to another.\n",
    "\n",
    "**That's why [xgcm](https://xgcm.readthedocs.io/en/latest/) was created.**\n",
    "\n",
    "Xgcm allows us to create a `Grid` object, which understands how to interpolate and take differences in a way that\n",
    "is compatible with finite volume models such at MITgcm. Xgcm also works with many other models, including ROMS,\n",
    "POP, MOM5/6, NEMO, etc.\n",
    "\n",
    "A second reason for this being hard is because of the complex topology connecting the different MITgcm faces.\n",
    "Fortunately, xgcm also [supports this](https://xgcm.readthedocs.io/en/latest/grid_topology.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'ds' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "Input \u001B[0;32mIn [16]\u001B[0m, in \u001B[0;36m<cell line: 31>\u001B[0;34m()\u001B[0m\n\u001B[1;32m      2\u001B[0m face_connections \u001B[38;5;241m=\u001B[39m {\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mface\u001B[39m\u001B[38;5;124m'\u001B[39m:\n\u001B[1;32m      3\u001B[0m                         {\u001B[38;5;241m0\u001B[39m: {\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mX\u001B[39m\u001B[38;5;124m'\u001B[39m:  ((\u001B[38;5;241m12\u001B[39m, \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mY\u001B[39m\u001B[38;5;124m'\u001B[39m, \u001B[38;5;28;01mFalse\u001B[39;00m), (\u001B[38;5;241m3\u001B[39m, \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mX\u001B[39m\u001B[38;5;124m'\u001B[39m, \u001B[38;5;28;01mFalse\u001B[39;00m)),\n\u001B[1;32m      4\u001B[0m                              \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mY\u001B[39m\u001B[38;5;124m'\u001B[39m:  (\u001B[38;5;28;01mNone\u001B[39;00m,             (\u001B[38;5;241m1\u001B[39m, \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mY\u001B[39m\u001B[38;5;124m'\u001B[39m, \u001B[38;5;28;01mFalse\u001B[39;00m))},\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m     27\u001B[0m                          \u001B[38;5;241m12\u001B[39m: {\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mX\u001B[39m\u001B[38;5;124m'\u001B[39m: ((\u001B[38;5;241m11\u001B[39m, \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mX\u001B[39m\u001B[38;5;124m'\u001B[39m, \u001B[38;5;28;01mFalse\u001B[39;00m), \u001B[38;5;28;01mNone\u001B[39;00m),\n\u001B[1;32m     28\u001B[0m                               \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mY\u001B[39m\u001B[38;5;124m'\u001B[39m: ((\u001B[38;5;241m9\u001B[39m, \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mY\u001B[39m\u001B[38;5;124m'\u001B[39m, \u001B[38;5;28;01mFalse\u001B[39;00m),  (\u001B[38;5;241m0\u001B[39m, \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mX\u001B[39m\u001B[38;5;124m'\u001B[39m, \u001B[38;5;28;01mFalse\u001B[39;00m))}}}\n\u001B[1;32m     30\u001B[0m \u001B[38;5;66;03m# create the grid object\u001B[39;00m\n\u001B[0;32m---> 31\u001B[0m grid \u001B[38;5;241m=\u001B[39m xgcm\u001B[38;5;241m.\u001B[39mGrid(\u001B[43mds\u001B[49m, periodic\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mFalse\u001B[39;00m, face_connections\u001B[38;5;241m=\u001B[39mface_connections)\n\u001B[1;32m     32\u001B[0m grid\n",
      "\u001B[0;31mNameError\u001B[0m: name 'ds' is not defined"
     ]
    }
   ],
   "source": [
    "# define the connectivity between faces\n",
    "face_connections = {'face':\n",
    "                        {0: {'X':  ((12, 'Y', False), (3, 'X', False)),\n",
    "                             'Y':  (None,             (1, 'Y', False))},\n",
    "                         1: {'X':  ((11, 'Y', False), (4, 'X', False)),\n",
    "                             'Y':  ((0, 'Y', False),  (2, 'Y', False))},\n",
    "                         2: {'X':  ((10, 'Y', False), (5, 'X', False)),\n",
    "                             'Y':  ((1, 'Y', False),  (6, 'X', False))},\n",
    "                         3: {'X':  ((0, 'X', False),  (9, 'Y', False)),\n",
    "                             'Y':  (None,             (4, 'Y', False))},\n",
    "                         4: {'X':  ((1, 'X', False),  (8, 'Y', False)),\n",
    "                             'Y':  ((3, 'Y', False),  (5, 'Y', False))},\n",
    "                         5: {'X':  ((2, 'X', False),  (7, 'Y', False)),\n",
    "                             'Y':  ((4, 'Y', False),  (6, 'Y', False))},\n",
    "                         6: {'X':  ((2, 'Y', False),  (7, 'X', False)),\n",
    "                             'Y':  ((5, 'Y', False),  (10, 'X', False))},\n",
    "                         7: {'X':  ((6, 'X', False),  (8, 'X', False)),\n",
    "                             'Y':  ((5, 'X', False),  (10, 'Y', False))},\n",
    "                         8: {'X':  ((7, 'X', False),  (9, 'X', False)),\n",
    "                             'Y':  ((4, 'X', False),  (11, 'Y', False))},\n",
    "                         9: {'X':  ((8, 'X', False),  None),\n",
    "                             'Y':  ((3, 'X', False),  (12, 'Y', False))},\n",
    "                         10: {'X': ((6, 'Y', False),  (11, 'X', False)),\n",
    "                              'Y': ((7, 'Y', False),  (2, 'X', False))},\n",
    "                         11: {'X': ((10, 'X', False), (12, 'X', False)),\n",
    "                              'Y': ((8, 'Y', False),  (1, 'X', False))},\n",
    "                         12: {'X': ((11, 'X', False), None),\n",
    "                              'Y': ((9, 'Y', False),  (0, 'X', False))}}}\n",
    "\n",
    "# create the grid object\n",
    "grid = xgcm.Grid(ds, periodic=False, face_connections=face_connections)\n",
    "grid"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can use the `grid` object we created to take the divergence of a 2D vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# vertical integral and time mean of horizontal diffusive heat flux\n",
    "advx_th_vint = ds.ADVx_TH.sum(dim='k').mean(dim='time')\n",
    "advy_th_vint = ds.ADVy_TH.sum(dim='k').mean(dim='time')\n",
    "\n",
    "# difference in the x and y directions\n",
    "diff_ADV_th = grid.diff_2d_vector({'X': advx_th_vint, 'Y': advy_th_vint}, boundary='fill')\n",
    "# convergence\n",
    "conv_ADV_th = -diff_ADV_th['X'] - diff_ADV_th['Y']\n",
    "conv_ADV_th"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# vertical integral and time mean of horizontal diffusive heat flux\n",
    "difx_th_vint = ds.DFxE_TH.sum(dim='k').mean(dim='time')\n",
    "dify_th_vint = ds.DFyE_TH.sum(dim='k').mean(dim='time')\n",
    "\n",
    "# difference in the x and y directions\n",
    "diff_DIF_th = grid.diff_2d_vector({'X': difx_th_vint, 'Y': dify_th_vint}, boundary='fill')\n",
    "# convergence\n",
    "conv_DIF_th = -diff_DIF_th['X'] - diff_DIF_th['Y']\n",
    "conv_DIF_th"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# convert to Watts / m^2 and load\n",
    "mean_adv_conv = rho0 * cp * (conv_ADV_th/coords.rA).fillna(0.).load()\n",
    "mean_dif_conv = rho0 * cp * (conv_DIF_th/coords.rA).fillna(0.).load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "ax = mapper(mean_adv_conv, cmap='RdBu_r', vmax=300, vmin=-300);\n",
    "ax.set_title(r'Convergence of Advective Flux (W/m$^2$)');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "ax = mapper(mean_dif_conv, cmap='RdBu_r', vmax=300, vmin=-300)\n",
    "ax.set_title(r'Convergence of Diffusive Flux (W/m$^2$)');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "ax = mapper(mean_dif_conv + mean_adv_conv, cmap='RdBu_r', vmax=300, vmin=-300)\n",
    "ax.set_title(r'Convergence of Net Horizontal Flux (W/m$^2$)');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "ax = mapper(ds.TFLUX.mean(dim='time').load(), cmap='RdBu_r', vmax=300, vmin=-300);\n",
    "ax.set_title(r'Surface Heat Flux (W/m$^2$)');\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  },
  "nbdime-conflicts": {
   "local_diff": [
    {
     "diff": [
      {
       "diff": [
        {
         "key": 0,
         "op": "addrange",
         "valuelist": [
          "Python 3"
         ]
        },
        {
         "key": 0,
         "length": 1,
         "op": "removerange"
        }
       ],
       "key": "display_name",
       "op": "patch"
      }
     ],
     "key": "kernelspec",
     "op": "patch"
    }
   ],
   "remote_diff": [
    {
     "diff": [
      {
       "diff": [
        {
         "key": 0,
         "op": "addrange",
         "valuelist": [
          "Python3"
         ]
        },
        {
         "key": 0,
         "length": 1,
         "op": "removerange"
        }
       ],
       "key": "display_name",
       "op": "patch"
      }
     ],
     "key": "kernelspec",
     "op": "patch"
    }
   ]
  },
  "toc-autonumbering": false
 },
 "nbformat": 4,
 "nbformat_minor": 4
}